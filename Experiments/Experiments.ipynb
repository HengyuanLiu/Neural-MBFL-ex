{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03036dc-18dd-4995-8260-fe1c0e2feb8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2, venn3\n",
    "from itertools import product\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dda1725-23ad-46e5-a62d-1a5e7b98a9a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from FLResultAnalyst import FLResultAnalyst\n",
    "from Utils.STEnvConfig import get_pathConfig\n",
    "from Utils.DatasetConfig import get_D4Jprojects, get_D4Jversions, get_SrcPath4D4J, get_TestCases4D4J \n",
    "from Utils.PandasHelper import move_column_to_pos, move_rows_with_value_to_end\n",
    "from Utils.ColorPalette import GenshinImpactColorPalette as GIColorPalette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8750141-1537-45d5-a908-171c15bb929f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pathConfig = get_pathConfig()\n",
    "if pathConfig:\n",
    "    D4J = Path(pathConfig[\"D4J\"])\n",
    "    MBFL_Metric = Path(pathConfig[\"MBFL_Metric\"])\n",
    "print(D4J.as_posix())\n",
    "print(MBFL_Metric.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01d78b9-099d-42cf-b974-38020b432073",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Granularity = [\"Statement\"]\n",
    "Dataset = [\"Defects4J\"]\n",
    "\n",
    "MutationType = [\"NeuralMutation\", \"TraditionalMutation\", \"MergeMutation\", \"MergeSus\"]\n",
    "Tool = {\n",
    "    \"NeuralMutation\": [\"mBERT\"],\n",
    "    \"TraditionalMutation\": [\"major\"],\n",
    "    \"MergeMutation\": [\"major_SmBERT\", \"mBERT_Smajor\", \"U_mBERT_major\"],\n",
    "    \"MergeSus\": [\"SusDRankAvg\"]\n",
    "}\n",
    "Approach = [\"FACombination\"]\n",
    "KillType = [\"kill_type3\"]\n",
    "Aggregation = [\"max\"]\n",
    "TieBreak = [\"Avg\"]\n",
    "Metric = [\"TopN\", \"EXAM\", \"MEAN\"]\n",
    "Formula = [\"Dstar\", \"Ochiai\", \"Jaccard\", \"Op2\", \"Tarantula\", \"Gp13\", \"Muse\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7eb272-e962-48d4-ad11-313c2c17b215",
   "metadata": {},
   "source": [
    "## **MTP (Mutant Test Pair)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fd3ec1-e835-4258-9026-bbe4fbe5e192",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_executed_mutant_count4mBERT(project, version):\n",
    "    from Utils.STEnvConfig import get_pathConfig\n",
    "    from Utils.DatasetConfig import get_SrcPath4D4J\n",
    "    from Utils.FileStatistic import get_files_with_suffix\n",
    "    pathConfig = get_pathConfig()\n",
    "    if pathConfig:\n",
    "        NeuralMutationResult = Path(pathConfig[\"NeuralMutationResult\"])\n",
    "    project_version_MutantRepoPath = NeuralMutationResult / \"mBERT\" / \"Defects4J/result4FaultFile_json\" / f\"{project}/{str(version)}b\"\n",
    "    \n",
    "    if not project_version_MutantRepoPath.exists():\n",
    "        return -1\n",
    "    else:\n",
    "        return len(get_files_with_suffix(project_version_MutantRepoPath, suffix=\".json\"))\n",
    "\n",
    "def get_executed_mutant_count4major(project, version):\n",
    "    from Utils.STEnvConfig import get_pathConfig\n",
    "    from Utils.DatasetConfig import get_SrcPath4D4J\n",
    "    from Utils.FileStatistic import get_files_with_suffix\n",
    "    pathConfig = get_pathConfig()\n",
    "    if pathConfig:\n",
    "        TraditionalMutationResult = Path(pathConfig[\"TraditionalMutationResult\"])\n",
    "    \n",
    "    if project in [\"Collections\", \"Compress\", \"JacksonDatabind\", \"Jsoup\", \"JxPath\"]:\n",
    "        project_version_MutantRepoPath = TraditionalMutationResult / \"major\" / \"Defects4J/result4FaultFile_json\" / f\"{project}/{str(version)}b\"\n",
    "    else:\n",
    "        project_version_MutantRepoPath = TraditionalMutationResult / \"major\" / \"Defects4J/result4FaultFile_json\" / f\"{project}/{str(version)}b\"\n",
    "\n",
    "    if not project_version_MutantRepoPath.exists():\n",
    "        return -1\n",
    "    else:\n",
    "        return len(get_files_with_suffix(project_version_MutantRepoPath, suffix=\".json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ede88d-7b49-400d-87b2-241b905c0dd3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "projects = get_D4Jprojects(DatasetVersion=\"v2.0\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for project in projects:\n",
    "    \n",
    "    versions = get_D4Jversions(project)\n",
    "    \n",
    "    mbert_total_MTP = 0\n",
    "    major_total_MTP = 0\n",
    "    mbert_num_versions = len(versions)\n",
    "    major_num_versions = len(versions)\n",
    "    \n",
    "    for version in versions:\n",
    "        print(f\"---------{project} {version}---------\")\n",
    "        \n",
    "        mbert_mutants = get_executed_mutant_count4mBERT(project, version)\n",
    "        major_mutants = get_executed_mutant_count4major(project, version)\n",
    "        \n",
    "        version_testcases = len(get_TestCases4D4J(project, version))\n",
    "        \n",
    "        if mbert_mutants == -1:\n",
    "            mbert_num_versions -= 1\n",
    "        else:\n",
    "            mbert_total_MTP += mbert_mutants * version_testcases\n",
    "            \n",
    "            print(f\"mBERT [MTP:{mbert_total_MTP}] [mutants:{mbert_mutants}] [testcases:{version_testcases}] \")\n",
    "            \n",
    "        if major_mutants == -1:\n",
    "            major_num_versions -= 1\n",
    "        else:\n",
    "            major_total_MTP += major_mutants * version_testcases\n",
    "            \n",
    "            print(f\"mBERT [MTP:{major_total_MTP}] [mutants:{major_mutants}] [testcases:{version_testcases}] \")\n",
    "    \n",
    "    mbert_avg_MTP = mbert_total_MTP / mbert_num_versions if mbert_num_versions > 0 else 0\n",
    "    major_avg_MTP = major_total_MTP / major_num_versions if major_num_versions > 0 else 0\n",
    "    \n",
    "    results.append([project, mbert_avg_MTP, major_avg_MTP])\n",
    "\n",
    "overall_mbert_avg_MTP = sum(row[1] for row in results) / len(results) if len(results) > 0 else 0\n",
    "overall_major_avg_MTP = sum(row[2] for row in results) / len(results) if len(results) > 0 else 0\n",
    "\n",
    "\n",
    "\n",
    "with open('./Results/MTP.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    \n",
    "    writer.writerow(['Project', 'mBERT Average MTP', 'Major Average MTP'])\n",
    "    \n",
    "    writer.writerows(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5894aee9-1549-48db-ac13-0c25d09bab69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "from Utils.ColorPalette import GenshinImpactColorPalette as GIColorPalette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc575462-0439-449b-a1e7-8a6b77fe4e1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "title_fontsize = 24\n",
    "label_fontsize = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8126f3f8-2dd4-44cc-8cfc-4ead493cda15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "palette_Tighnari = GIColorPalette.get_palette('Tighnari', format=\"hex\")\n",
    "palette_Nilou = GIColorPalette.get_palette('Nilou', format=\"hex\")\n",
    "palette_6 = [palette_Tighnari[5], palette_Tighnari[2], palette_Tighnari[7], palette_Tighnari[1], palette_Tighnari[9], palette_Nilou[4]]\n",
    "palette_2 = palette_6[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354336c5-af08-45fd-817c-2151eb131626",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flra = FLResultAnalyst()\n",
    "flra.DatasetVersion[flra.dataset]=\"v2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283b521b-8243-479f-ba67-b1152634bb6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Results/MTP.csv')\n",
    "overall_data = data[data['Project'] == 'Overall']\n",
    "measurements = overall_data[['Major Average MTP', 'mBERT Average MTP']].iloc[0]\n",
    "labels = ['Traditional-MBFL', 'Neural-MBFL']\n",
    "x = [0.5 * x for x in np.arange(len(labels))]  \n",
    "width = 0.35  \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "rects = ax.bar(x, measurements, width, color=palette_2)\n",
    "\n",
    "ax.bar_label(rects, padding=3, fmt='%.0f', fontsize=label_fontsize)\n",
    "\n",
    "ax.set_ylabel('Mutant-Test Pair (MTP)', fontsize=label_fontsize)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, fontsize=label_fontsize)\n",
    "ax.tick_params(axis='both', labelsize=label_fontsize)\n",
    "ax.set_ylim(0, 1200000)  \n",
    "plt.gca().get_yaxis().get_major_formatter().set_scientific(False)  \n",
    "\n",
    "plt.savefig(\"./Results/MTP/MTP.pdf\", bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0f76e1-ecea-496d-914b-79c611dcff36",
   "metadata": {},
   "source": [
    "## **Top-N, MAP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b331c353-afcb-43df-a79a-730211832033",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flra = FLResultAnalyst()\n",
    "param = {\n",
    "    \"Kill Type\": [\"kill_type3\"],\n",
    "    \"Approach\": [\"FACombination\"],\n",
    "    \"Mutation Type\": [\"NeuralMutation\", \"TraditionalMutation\", \"MergeMutation\", \"MergeSus\"],\n",
    "    \"Mutation Method\": [\"major\", \"mBERT\", \"major_SmBERT\", \"mBERT_Smajor\", \"U_mBERT_major\", \"SusDRankAvg\"],\n",
    "    \"Aggregation\": [\"max\"],\n",
    "    \"Formula\": [\"Dstar\", \"Ochiai\", \"Jaccard\", \"Op2\", \"Tarantula\", \"Gp13\", \"Muse\"],\n",
    "    \"Tie Break\": [\"Avg\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93b0b46-8f1d-48f8-b2d5-d61c2545091c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flra.DatasetVersion[flra.dataset]=\"v2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eebaf7-af7d-4aa2-ac72-29183a97fa03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_summary_dfs = flra.compare_topn_mean_summary_by_param(param)\n",
    "\n",
    "reorder_col = [\n",
    "    'Dataset', 'Granularity', 'Project', 'Kill Type', 'Approach',\n",
    "    'Aggregation', 'Tie Break', 'Formula', 'Mutation Type', 'Mutation Method', \n",
    "    'top1', 'top3', 'top5', 'MAP',\n",
    "]\n",
    "all_summary_dfs = all_summary_dfs[reorder_col]\n",
    "\n",
    "rename_col = {\n",
    "    'top1': 'Top1',\n",
    "    'top3': 'Top3',\n",
    "    'top5': 'Top5',\n",
    "}\n",
    "all_summary_dfs = all_summary_dfs.rename(columns=rename_col)\n",
    "\n",
    "MutationMethodOrder = [\"major\", \"mBERT\", \"major_SmBERT\", \"mBERT_Smajor\", \"U_mBERT_major\", \"SusDRankAvg\"]\n",
    "all_summary_dfs[\"Mutation Method\"] = pd.Categorical(\n",
    "    all_summary_dfs[\"Mutation Method\"], \n",
    "    categories=MutationMethodOrder, ordered=True\n",
    ")\n",
    "FormulaOrder = [\"Dstar\", \"Ochiai\", \"Jaccard\", \"Op2\", \"Tarantula\", \"Gp13\", \"Muse\"]\n",
    "all_summary_dfs[\"Formula\"] = pd.Categorical(\n",
    "    all_summary_dfs[\"Formula\"], \n",
    "    categories=FormulaOrder, ordered=True\n",
    ")\n",
    "all_summary_dfs = all_summary_dfs.sort_values(by=[\"Formula\", \"Mutation Method\"], ascending=[True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cf8a22-510e-43c4-9d7c-f4f515ef49b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_dfs = all_summary_dfs[(all_summary_dfs[\"Project\"] == \"Summary\")]\n",
    "summary_dfs_grouped = summary_dfs.groupby(\n",
    "    # 'Mutation Method'\n",
    "    [\n",
    "        'Dataset', 'Granularity', 'Project', 'Kill Type', 'Approach',\n",
    "        'Aggregation', 'Tie Break', 'Mutation Type', 'Mutation Method',\n",
    "    ]\n",
    "    , observed=True\n",
    ").agg({\n",
    "    \"Formula\": lambda x: \"Avg.\", \n",
    "    \"Top1\": 'mean',\n",
    "    \"Top3\": 'mean',\n",
    "    \"Top5\": 'mean',\n",
    "    \"MAP\": 'mean',\n",
    "}).reset_index()\n",
    "summary_dfs = pd.concat([summary_dfs, summary_dfs_grouped], ignore_index=True)\n",
    "\n",
    "FormulaOrder = [\"Dstar\", \"Ochiai\", \"Jaccard\", \"Op2\", \"Tarantula\", \"Gp13\", \"Muse\", \"Avg.\"]\n",
    "summary_dfs[\"Formula\"] = pd.Categorical(\n",
    "    summary_dfs[\"Formula\"], \n",
    "    categories=FormulaOrder, ordered=True\n",
    ")\n",
    "summary_dfs = summary_dfs.sort_values(by=[\"Formula\", \"Mutation Method\"], ascending=[True, True], ignore_index=True)\n",
    "\n",
    "MutationMethodNameMap = {\n",
    "    \"major\":\"Traditional-MBFL\",\n",
    "    \"mBERT\":\"Neural-MBFL\",\n",
    "    \"major_SmBERT\":\"NeuraIntegra-MBFL$_{Mutation}^{Traditional-Center}$\",\n",
    "    \"mBERT_Smajor\":\"NeuraIntegra-MBFL$_{Mutation}^{Neural-Center}$\",\n",
    "    \"U_mBERT_major\":\"NeuraIntegra-MBFL$_{Mutation}^{Union}$\",\n",
    "    \"SusDRankAvg\":\"NeuraIntegra-MBFL$_{Suspiciousness}$\",\n",
    "}\n",
    "summary_dfs[\"Mutation Method\"] = summary_dfs[\"Mutation Method\"].cat.rename_categories(MutationMethodNameMap)\n",
    "\n",
    "summary_dfs = summary_dfs.rename(columns={\"Mutation Method\": \"Technique\"})\n",
    "\n",
    "summary_dfs[summary_dfs[\"Project\"] == \"Summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd44573-ee31-4af2-bb63-28c8130c91ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agg_type = param[\"Aggregation\"][0].upper()\n",
    "summary_dfs_6 = summary_dfs[['Formula', 'Technique', 'Top1', 'Top3', 'Top5', 'MAP']]\n",
    "summary_dfs_6.to_csv(f\"./Results/TopN_MEAN_6_{agg_type}.csv\", index=False)\n",
    "summary_dfs_2 = summary_dfs_6[summary_dfs_6[\"Technique\"].isin([\"Traditional-MBFL\", \"Neural-MBFL\"])]\n",
    "summary_dfs_2.to_csv(f\"./Results/TopN_MEAN_2_{agg_type}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f45dc9b-72e4-4d0f-8b31-d4b3177d91fc",
   "metadata": {},
   "source": [
    "## **EXAM Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cf5c7e-fdde-4bc8-a497-7c83e81de5cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flra = FLResultAnalyst()\n",
    "param = {\n",
    "    \"Kill Type\": [\"kill_type3\"],\n",
    "    \"Approach\": [\"FACombination\"],\n",
    "    \"Mutation Type\": [\"NeuralMutation\", \"TraditionalMutation\", \"MergeMutation\", \"MergeSus\"],\n",
    "    \"Mutation Method\": [\"major\", \"mBERT\", \"major_SmBERT\", \"mBERT_Smajor\", \"U_mBERT_major\", \"SusDRankAvg\"],\n",
    "    \"Aggregation\": [\"max\"],\n",
    "    \"Formula\": [\"Dstar\", \"Ochiai\", \"Jaccard\", \"Op2\", \"Tarantula\", \"Gp13\", \"Muse\"],\n",
    "    \"Tie Break\": [\"Avg\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46136f5-6a9f-440a-bd1e-ab2e28df4b50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flra.DatasetVersion[flra.dataset]=\"v2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea70989-887c-4843-ae6b-e508cb567204",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exam_summary_dfs = flra.compare_exam_summary_by_param(param, independent_variable=\"Mutation Method\", drop_rank=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c21f838-aee6-45b0-a64d-d7ac71607d34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exam_summary_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cb6173-0a35-4378-ae15-58b3afb30409",
   "metadata": {},
   "source": [
    "### **EXAM Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f33ed3-c20f-401d-94b7-061fce4d47c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "from Utils.ColorPalette import GenshinImpactColorPalette as GIColorPalette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75ca7c8-6238-444f-ade2-bc3d7050dd39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "title_fontsize = 36\n",
    "label_fontsize = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd39591-7b5a-4f36-8f13-a986a91c41fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "palette_Tighnari = GIColorPalette.get_palette('Tighnari')\n",
    "palette_Nilou = GIColorPalette.get_palette('Nilou')\n",
    "palette_6 = [palette_Tighnari[5], palette_Tighnari[2], palette_Tighnari[7], palette_Tighnari[1], palette_Tighnari[9], palette_Nilou[4]]\n",
    "palette_2 = palette_6[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac503586-221f-4f1d-91c8-f3f5b09ae752",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GIColorPalette.show_palette('Tighnari')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b9ae69-a193-4ad4-91ee-432394d11aa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GIColorPalette.show_palette('Nilou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccfbbe0-6fa5-4c49-ba2b-38b78192c8e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.palplot(palette_6)\n",
    "plt.title(\"Color Palette\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9832a222-e6dd-4581-a3ad-3f2c464e7022",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flra = FLResultAnalyst()\n",
    "flra.DatasetVersion[flra.dataset]=\"v2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b7d792-54f3-408c-8168-03e61fe11945",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TechniqueNameMap = {\n",
    "    \"EXAM_major\":\"Traditional-MBFL\",\n",
    "    \"EXAM_mBERT\":\"Neural-MBFL\",\n",
    "    \"EXAM_major_SmBERT\":\"NeuraIntegra-MBFL$_{Mutation}^{Traditional-Center}$\",\n",
    "    \"EXAM_mBERT_Smajor\":\"NeuraIntegra-MBFL$_{Mutation}^{Neural-Center}$\",\n",
    "    \"EXAM_U_mBERT_major\":\"NeuraIntegra-MBFL$_{Mutation}^{Union}$\",\n",
    "    \"EXAM_SusDRankAvg\":\"NeuraIntegra-MBFL$_{Suspiciousness}$\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8eb4ab-90a7-4a7b-8f16-11f488daa0ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for formula_index, formula in enumerate(flra.Formula):\n",
    "    param = {\n",
    "        \"Kill Type\": [\"kill_type3\"],\n",
    "        \"Approach\": [\"FACombination\"],\n",
    "        \"Mutation Type\": [\"MergeSus\", \"MergeMutation\", \"NeuralMutation\", \"TraditionalMutation\"],\n",
    "        \"Mutation Method\": [\"major\", \"mBERT\", \"major_SmBERT\", \"mBERT_Smajor\", \"U_mBERT_major\", \"SusDRankAvg\"],\n",
    "        \"Aggregation\": [\"max\"],\n",
    "        \"Formula\": [formula],\n",
    "        \"Tie Break\": [\"Avg\"]\n",
    "    }\n",
    "\n",
    "    exam_summary_dfs = flra.compare_exam_summary_by_param(param, \"Mutation Method\", drop_rank=False)\n",
    "    exam_columns = [col for col in exam_summary_dfs.columns if col.startswith('EXAM_')]\n",
    "    exam_summary_dfs[exam_columns] = exam_summary_dfs[exam_columns].fillna(value=1)\n",
    "\n",
    "    \n",
    "    exam_columns = [col for col in exam_summary_dfs.columns if col.startswith('EXAM_')]\n",
    "    columns4analysis = [exam_columns[i] for i in [5, 4, 1, 2, 3, 0]]\n",
    "    \n",
    "    \n",
    "    fig, axs = plt.subplots(1, 4, figsize=(42, 6))\n",
    "\n",
    "    \n",
    "    handles_labels_first = []\n",
    "    handles_labels_second = []\n",
    "\n",
    "    \n",
    "    for column_index, column in enumerate(columns4analysis):\n",
    "        color = palette_6[column_index]\n",
    "        data = exam_summary_dfs[column].dropna()  \n",
    "\n",
    "        \n",
    "        x = np.linspace(data.min() - 3, data.max() + 3, 1000)\n",
    "\n",
    "        \n",
    "        kde = gaussian_kde(data)\n",
    "        pdf = kde.evaluate(x)\n",
    "        cdf = np.cumsum(pdf)\n",
    "        cdf /= cdf[-1]  \n",
    "\n",
    "        \n",
    "        sns.kdeplot(data, bw_adjust=0.5, label=TechniqueNameMap[column], fill=True, color=color, alpha=0.05, ax=axs[0])\n",
    "        axs[0].set_title('Probability Density Function', fontsize=title_fontsize)\n",
    "        axs[0].tick_params(axis='both', labelsize=label_fontsize)\n",
    "        axs[0].set_xlabel('EXAM', fontsize=label_fontsize)\n",
    "        axs[0].set_ylabel('Density', fontsize=label_fontsize)\n",
    "        \n",
    "\n",
    "        \n",
    "        bins = 25  \n",
    "        sns.histplot(data, stat='probability', bins=bins, label=TechniqueNameMap[column], element='step', common_norm=False, color=color, alpha=0.05, ax=axs[1])\n",
    "        axs[1].set_title('Probability Distribution Function', fontsize=title_fontsize)\n",
    "        axs[1].tick_params(axis='both', labelsize=label_fontsize)\n",
    "        axs[1].set_xlabel('EXAM', fontsize=label_fontsize)\n",
    "        axs[1].set_ylabel('Probability', fontsize=label_fontsize)\n",
    "        \n",
    "        \n",
    "        \n",
    "        handles_labels_first.append(axs[0].get_legend_handles_labels())\n",
    "\n",
    "        \n",
    "        sns.ecdfplot(data, label=TechniqueNameMap[column], color=color, alpha=0.5, ax=axs[2])\n",
    "        axs[2].set_title('Empirical Cumulative Distribution Function', fontsize=title_fontsize)\n",
    "        axs[2].tick_params(axis='both', labelsize=label_fontsize)\n",
    "        axs[2].set_xlabel('EXAM', fontsize=label_fontsize)\n",
    "        axs[2].set_ylabel('Cumulative Probability', fontsize=label_fontsize)\n",
    "\n",
    "        \n",
    "        axs[3].plot(x, cdf, label=TechniqueNameMap[column], color=color, alpha=0.5)\n",
    "        axs[3].set_title('Smooth Cumulative Distribution Function', fontsize=title_fontsize)\n",
    "        axs[3].tick_params(axis='both', labelsize=label_fontsize)\n",
    "        axs[3].set_xlabel('EXAM', fontsize=label_fontsize)\n",
    "        axs[3].set_ylabel('Cumulative Probability', fontsize=label_fontsize)\n",
    "        axs[3].set_xlim(-0.25, 1.25)\n",
    "        \n",
    "        \n",
    "        handles_labels_second.append(axs[2].get_legend_handles_labels())\n",
    "    \n",
    "    if formula_index == 0:\n",
    "        handles, labels = axs[0].get_legend_handles_labels()\n",
    "        fig.legend(handles, labels, loc='upper center', ncol=3, bbox_to_anchor=(0.25, 1.26), fontsize=label_fontsize)\n",
    "        \n",
    "        handles, labels = axs[2].get_legend_handles_labels()\n",
    "        fig.legend(handles, labels, loc='upper center', ncol=3, bbox_to_anchor=(0.75, 1.26), fontsize=label_fontsize)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "    plt.savefig(f'./Results/EXAM/EXAM_6_{formula}.pdf', bbox_inches='tight', pad_inches=0.1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eb3561-dfe6-4702-a5a8-b30820f84fd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for formula_index, formula in enumerate(flra.Formula):\n",
    "    param = {\n",
    "        \"Kill Type\": [\"kill_type3\"],\n",
    "        \"Approach\": [\"FACombination\"],\n",
    "        \"Mutation Type\": [\"TraditionalMutation\", \"NeuralMutation\"],\n",
    "        \"Mutation Method\": [\"major\", \"mBERT\"],\n",
    "        \"Aggregation\": [\"max\"],\n",
    "        \"Formula\": [formula],\n",
    "        \"Tie Break\": [\"Avg\"]\n",
    "    }\n",
    "\n",
    "    exam_summary_dfs = flra.compare_exam_summary_by_param(param, \"Mutation Method\", drop_rank=False)\n",
    "    exam_columns = [col for col in exam_summary_dfs.columns if col.startswith('EXAM_')]\n",
    "    exam_summary_dfs[exam_columns] = exam_summary_dfs[exam_columns].fillna(value=1)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(42, 6))\n",
    "    \n",
    "    for column_index, column in enumerate(exam_columns):\n",
    "        color = palette_2[column_index]\n",
    "        data = exam_summary_dfs[column].dropna()  \n",
    "\n",
    "        x = np.linspace(data.min() - 3, data.max() + 3, 1000)\n",
    "\n",
    "        kde = gaussian_kde(data)\n",
    "        pdf = kde.evaluate(x)\n",
    "        cdf = np.cumsum(pdf)\n",
    "        cdf /= cdf[-1]  \n",
    "        \n",
    "        sns.kdeplot(data, bw_adjust=0.5, label=TechniqueNameMap[column], fill=True, color=color, alpha=0.05, ax=axs[0])\n",
    "        axs[0].set_title('Probability Density Function', fontsize=title_fontsize)\n",
    "        axs[0].tick_params(axis='both', labelsize=label_fontsize)\n",
    "        axs[0].set_xlabel('EXAM', fontsize=label_fontsize)\n",
    "        axs[0].set_ylabel('Density', fontsize=label_fontsize)\n",
    "        axs[0].set_ylim(0.0, 3.6)\n",
    "        \n",
    "        bins = 25  \n",
    "        sns.histplot(data, stat='probability', bins=bins, label=TechniqueNameMap[column], element='step', common_norm=False, color=color, alpha=0.05, ax=axs[1])\n",
    "        axs[1].set_title('Probability Distribution Function', fontsize=title_fontsize)\n",
    "        axs[1].tick_params(axis='both', labelsize=label_fontsize)\n",
    "        axs[1].set_xlabel('EXAM', fontsize=label_fontsize)\n",
    "        axs[1].set_ylabel('Probability', fontsize=label_fontsize)\n",
    "        axs[1].set_ylim(0.0, 0.27)\n",
    "\n",
    "        \n",
    "        sns.ecdfplot(data, label=TechniqueNameMap[column], color=color, alpha=0.5, ax=axs[2])\n",
    "        axs[2].set_title('Empirical Cumulative Distribution Function', fontsize=title_fontsize)\n",
    "        axs[2].tick_params(axis='both', labelsize=label_fontsize)\n",
    "        axs[2].set_xlabel('EXAM', fontsize=label_fontsize)\n",
    "        axs[2].set_ylabel('Cumulative Probability', fontsize=label_fontsize)\n",
    "\n",
    "        \n",
    "        axs[3].plot(x, cdf, label=TechniqueNameMap[column], color=color, alpha=0.5)\n",
    "        axs[3].set_title('Smooth Cumulative Distribution Function', fontsize=title_fontsize)\n",
    "        axs[3].tick_params(axis='both', labelsize=label_fontsize)\n",
    "        axs[3].set_xlabel('EXAM', fontsize=label_fontsize)\n",
    "        axs[3].set_ylabel('Cumulative Probability', fontsize=label_fontsize)\n",
    "        axs[3].set_xlim(-0.25, 1.25)\n",
    "        \n",
    "    if formula_index == 0:\n",
    "        handles, labels = axs[1].get_legend_handles_labels()\n",
    "        fig.legend(handles, labels, loc='upper center', ncol=2, bbox_to_anchor=(0.25, 1.11), fontsize=label_fontsize)\n",
    "        \n",
    "        handles, labels = axs[3].get_legend_handles_labels()\n",
    "        fig.legend(handles, labels, loc='upper center', ncol=2, bbox_to_anchor=(0.75, 1.11), fontsize=label_fontsize)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    \n",
    "    plt.savefig(f'./Results/EXAM/EXAM_2_{formula}.pdf', bbox_inches='tight', pad_inches=0.1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a989458-fbd1-40b6-9c71-d11febad5e0b",
   "metadata": {},
   "source": [
    "### **Correlation Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3b3cff-6bd3-4012-bcad-163a31844b77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from scipy import stats\n",
    "import dcor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e5cf61-7278-4c18-ae2d-dffbfb395af8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "\n",
    "title_fontsize = 40\n",
    "label_fontsize = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c2ffa1-7d4c-4321-a639-78da9c7d6d1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import fitz  \n",
    "\n",
    "def crop_pdf(input_pdf_path, output_pdf_path, left=0, right=0, top=0, bottom=0):\n",
    "    doc = fitz.open(input_pdf_path)\n",
    "\n",
    "    for page in doc:\n",
    "        rect = page.rect\n",
    "        new_rect = fitz.Rect(rect.x0 + left, rect.y0 + top, rect.x1 - right, rect.y1 - bottom)\n",
    "        page.set_cropbox(new_rect)\n",
    "\n",
    "    doc.save(output_pdf_path)\n",
    "    doc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2da61aa-7132-415d-83ec-ab2ff0b62c26",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for formula_index, formula in enumerate(flra.Formula):\n",
    "    param = {\n",
    "        \"Kill Type\": [\"kill_type3\"],\n",
    "        \"Approach\": [\"FACombination\"],\n",
    "        \"Mutation Type\": [\"TraditionalMutation\", \"NeuralMutation\"],\n",
    "        \"Mutation Method\": [\"major\", \"mBERT\"],\n",
    "        \"Aggregation\": [\"max\"],\n",
    "        \"Formula\": [formula],\n",
    "        \"Tie Break\": [\"Avg\"]\n",
    "    }\n",
    "\n",
    "    exam_summary_dfs = flra.compare_exam_summary_by_param(param, \"Mutation Method\", drop_rank=False)\n",
    "    exam_columns = [col for col in exam_summary_dfs.columns if col.startswith('EXAM_')]\n",
    "    exam_summary_dfs[exam_columns] = exam_summary_dfs[exam_columns].fillna(value=1)\n",
    "    \n",
    "    correlation = exam_summary_dfs['EXAM_mBERT'].corr(exam_summary_dfs['EXAM_major'], method='kendall')\n",
    "    print(f'The number of point include in the analysis: {exam_summary_dfs.shape[0]}')\n",
    "    print(f'The correlation between EXAM_mBERT and EXAM_major is: {correlation:.4f}')\n",
    "    \n",
    "    distance_corr = dcor.distance_correlation(exam_summary_dfs['EXAM_mBERT'], exam_summary_dfs['EXAM_major'])\n",
    "    print(f\"Distance Correlation between EXAM_mBERT and EXAM_major: {distance_corr:.4f}\")\n",
    "    \n",
    "    data = exam_summary_dfs[['EXAM_mBERT', 'EXAM_major']].values.T\n",
    "    kde = stats.gaussian_kde(data)\n",
    "    density = kde(data)\n",
    "    vmin, vmax = density.min(), density.max()\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(16, 12))\n",
    "\n",
    "    reversed_cmap = custom_cmap.reversed()  # 假设 custom_cmap 是你的原始颜色映射变量名\n",
    "    \n",
    "    sns.scatterplot(x='EXAM_mBERT', y='EXAM_major', data=exam_summary_dfs, alpha=1, s=100, c=density, cmap=reversed_cmap)\n",
    "    \n",
    "    norm = plt.Normalize(vmin=0, vmax=vmax)\n",
    "    sm = plt.cm.ScalarMappable(cmap=reversed_cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, ax=ax, ticks=np.arange(0, vmax + 0.25, 0.25))\n",
    "    cbar.set_label('Density', fontsize=label_fontsize)\n",
    "    cbar.ax.tick_params(axis='both', labelsize=label_fontsize)\n",
    "\n",
    "    plt.xlabel('EXAM of Neural-MBFL', fontsize=label_fontsize)\n",
    "    plt.ylabel('EXAM of Traditional-MBFL', fontsize=label_fontsize)\n",
    "    ax.tick_params(axis='both', labelsize=label_fontsize)\n",
    "    plt.xlim(-0.02, 1.02)\n",
    "    plt.ylim(-0.02, 1.02)\n",
    "    \n",
    "    textstr = (\n",
    "        r\"$\\bf{Distance\\ Correlation\\ Analysis\\ of\\ EXAM}$\" + \"\\n\"\n",
    "        \"Neural-MBFL and Traditional-MBFL\" + f\": {distance_corr:.4f}\"\n",
    "    )\n",
    "\n",
    "    ax.text(-0.05, 1.15, textstr, transform=ax.transAxes, fontsize=label_fontsize,\n",
    "              verticalalignment='top', bbox=dict(boxstyle='round,pad=0.2', facecolor='white', edgecolor='black', alpha=0.5))\n",
    "    \n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'./Results/CorrAnalysis/CorrAnalysis_2_{formula}.pdf', bbox_inches='tight', pad_inches=0.15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f289000d-f39f-426f-8f3e-ad2bcb9e0bd4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for formula_index, formula in enumerate(flra.Formula):\n",
    "    param = {\n",
    "        \"Kill Type\": [\"kill_type3\"],\n",
    "        \"Approach\": [\"FACombination\"],\n",
    "        \"Mutation Type\": [\"TraditionalMutation\", \"NeuralMutation\", \"MergeSus\"],\n",
    "        \"Mutation Method\": [\"major\", \"mBERT\", \"SusDRankAvg\"],\n",
    "        \"Aggregation\": [\"max\"],\n",
    "        \"Formula\": [formula],\n",
    "        \"Tie Break\": [\"Avg\"]\n",
    "    }\n",
    "\n",
    "    exam_summary_dfs = flra.compare_exam_summary_by_param(param, \"Mutation Method\", drop_rank=False)\n",
    "    exam_columns = [col for col in exam_summary_dfs.columns if col.startswith('EXAM_')]\n",
    "    exam_summary_dfs[exam_columns] = exam_summary_dfs[exam_columns].fillna(value=1)\n",
    "\n",
    "    x = exam_summary_dfs['EXAM_mBERT'].values\n",
    "    y = exam_summary_dfs['EXAM_major'].values\n",
    "    z = exam_summary_dfs['EXAM_SusDRankAvg'].values\n",
    "\n",
    "    corr_mbert_susdrank = exam_summary_dfs['EXAM_SusDRankAvg'].corr(exam_summary_dfs['EXAM_mBERT'], method='pearson')\n",
    "    corr_major_susdrank = exam_summary_dfs['EXAM_SusDRankAvg'].corr(exam_summary_dfs['EXAM_major'], method='pearson')\n",
    "    print(f'The number of point include in the analysis: {exam_summary_dfs.shape[0]}')\n",
    "    print(f\"Correlation between EXAM_mBERT and EXAM_SusDRankAvg: {corr_mbert_susdrank:.2f}\")\n",
    "    print(f\"Correlation between EXAM_major and EXAM_SusDRankAvg: {corr_major_susdrank:.2f}\")\n",
    "    \n",
    "    distance_corr_mbert_susdrank = dcor.distance_correlation(exam_summary_dfs['EXAM_SusDRankAvg'], exam_summary_dfs['EXAM_mBERT'])\n",
    "    distance_corr_major_susdrank = dcor.distance_correlation(exam_summary_dfs['EXAM_SusDRankAvg'], exam_summary_dfs['EXAM_major'])\n",
    "    distance_corr_mbertmajor_susdrank = dcor.distance_correlation(\n",
    "        exam_summary_dfs[['EXAM_mBERT', 'EXAM_major']].values, \n",
    "        exam_summary_dfs['EXAM_SusDRankAvg'].values\n",
    "    )\n",
    "    print(f\"Distance Correlation between EXAM_mBERT and EXAM_SusDRankAvg: {distance_corr_mbert_susdrank:.4f}\")\n",
    "    print(f\"Distance Correlation between EXAM_major and EXAM_SusDRankAvg: {distance_corr_major_susdrank:.4f}\")\n",
    "    print(f\"Distance Correlation between EXAM_mBERT with EXAM_major and EXAM_SusDRankAvg: {distance_corr_mbertmajor_susdrank:.4f}\")\n",
    "    \n",
    "    \n",
    "    correlation_matrix = exam_summary_dfs[['EXAM_mBERT', 'EXAM_major', 'EXAM_SusDRankAvg']].corr(method='pearson')\n",
    "    print(correlation_matrix)\n",
    "\n",
    "    data = np.vstack([x, y, z])\n",
    "    kde = stats.gaussian_kde(data)\n",
    "\n",
    "    xi, yi = np.mgrid[0:1:100j, 0:1:100j]\n",
    "    zi_levels = 5\n",
    "    zi_values = [i / zi_levels for i in range(zi_levels + 1)]  \n",
    "\n",
    "    fig = plt.figure(figsize=(30, 30))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    reversed_cmap = custom_cmap.reversed()  \n",
    "    \n",
    "    scatter = ax.scatter(x, y, z, s=100, c=kde(data), cmap=reversed_cmap, alpha=1)\n",
    "    cbar = fig.colorbar(scatter, ax=ax, pad=0.1, shrink=0.5)\n",
    "    cbar.set_label('Density', fontsize=label_fontsize)\n",
    "    cbar.ax.tick_params(axis='both', labelsize=label_fontsize)\n",
    "\n",
    "    label_pad_var = 20\n",
    "    ax.set_xlabel('EXAM of Neural-MBFL', fontsize=label_fontsize, labelpad=label_pad_var+4)\n",
    "    ax.set_ylabel('EXAM of Traditional-MBFL', fontsize=label_fontsize, labelpad=label_pad_var+2)\n",
    "    ax.set_zlabel('EXAM of NeuraIntegra-MBFL$_{Suspiciousness}$', fontsize=label_fontsize, labelpad=label_pad_var)\n",
    "    ax.set_xlim(-0.02, 1.02)\n",
    "    ax.set_ylim(-0.02, 1.02)\n",
    "    ax.set_zlim(-0.02, 1.02)\n",
    "    ax.view_init(elev=15, azim=240)\n",
    "    \n",
    "    ax.tick_params(axis='both', labelsize=label_fontsize)\n",
    "    ax.zaxis.set_ticks_position('lower')\n",
    "    ax.zaxis.set_label_position('lower')\n",
    "    \n",
    "    textstr = (\n",
    "        r\"                       $\\bf{Distance\\ Correlation\\ Analysis\\ of\\ EXAM}$\" + \"\\n\"\n",
    "        \"NeuraIntegra-MBFL$_{Suspiciousness}$ and                                    Neural-MBFL\" + f\": {distance_corr_mbert_susdrank:.4f}\\n\"\n",
    "        \"NeuraIntegra-MBFL$_{Suspiciousness}$ and                             Traditional-MBFL\" + f\": {distance_corr_major_susdrank:.4f}\\n\"\n",
    "        \"NeuraIntegra-MBFL$_{Suspiciousness}$ and (Neural-MBFL, Traditional-MBFL)\" + f\": {distance_corr_mbertmajor_susdrank:.4f}\"\n",
    "    )\n",
    "\n",
    "    ax.text2D(0.045, 1.00, textstr, transform=ax.transAxes, fontsize=label_fontsize+8,\n",
    "              verticalalignment='top', bbox=dict(boxstyle='round,pad=0.2', facecolor='white', edgecolor='black', alpha=0.5))\n",
    "\n",
    "\n",
    "    plt.grid(True)\n",
    "    input_pdf = f'./Results/CorrAnalysis/CorrAnalysis_3D_{formula}_ori.pdf'\n",
    "    output_pdf = f'./Results/CorrAnalysis/CorrAnalysis_3D_{formula}.pdf'\n",
    "    plt.savefig(input_pdf, bbox_inches='tight', pad_inches=0.2)\n",
    "    \n",
    "    crop_pdf(input_pdf, output_pdf, left=50, right=0, top=0, bottom=140)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a73015-5319-4ce9-a869-17c47b065636",
   "metadata": {},
   "source": [
    "### **Statistic Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43bd21e-a2ee-40cd-8d49-e7ce535aa6f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import wilcoxon\n",
    "from StatisticAnalysis import summary_statistics, cliffs_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a71d09d-0698-4d3e-b639-1ec4de23ac0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flra = FLResultAnalyst()\n",
    "flra.DatasetVersion[flra.dataset]=\"v2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff358d4-78f8-4fc5-9a34-0aec24f65dbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TechniqueNameMap = {\n",
    "    \"EXAM_major\":\"Traditional-MBFL\",\n",
    "    \"EXAM_mBERT\":\"Neural-MBFL\",\n",
    "    \"EXAM_major_SmBERT\":\"NeuraIntegra-MBFL$_{Mutation}^{Traditional-Center}$\",\n",
    "    \"EXAM_mBERT_Smajor\":\"NeuraIntegra-MBFL$_{Mutation}^{Neural-Center}$\",\n",
    "    \"EXAM_U_mBERT_major\":\"NeuraIntegra-MBFL$_{Mutation}^{Union}$\",\n",
    "    \"EXAM_SusDRankAvg\":\"NeuraIntegra-MBFL$_{Suspiciousness}$\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5d9881-af02-4697-9003-d34e27c52e6d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns = ['Formula', 'Comparison', \n",
    "           'P-value (two-sided)', 'P-value (one-sided less)', 'P-value (one-sided greater)', \n",
    "           'Cliff\\'s Delta']\n",
    "results_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for formula_index, formula in enumerate(flra.Formula):\n",
    "    param = {\n",
    "        \"Kill Type\": [\"kill_type3\"],\n",
    "        \"Approach\": [\"FACombination\"],\n",
    "        \"Mutation Type\": [\"MergeSus\", \"MergeMutation\", \"NeuralMutation\", \"TraditionalMutation\"],\n",
    "        \"Mutation Method\": [\"major\", \"mBERT\", \"major_SmBERT\", \"mBERT_Smajor\", \"U_mBERT_major\", \"SusDRankAvg\"],\n",
    "        \"Aggregation\": [\"max\"],\n",
    "        \"Formula\": [formula],\n",
    "        \"Tie Break\": [\"Avg\"]\n",
    "    }\n",
    "\n",
    "    exam_summary_dfs = flra.compare_exam_summary_by_param(param, \"Mutation Method\", drop_rank=False)\n",
    "    exam_columns = [col for col in exam_summary_dfs.columns if col.startswith('EXAM_')]\n",
    "    exam_columns = [exam_columns[i] for i in [0, 5, 4, 1, 2, 3]]\n",
    "    exam_summary_dfs[exam_columns] = exam_summary_dfs[exam_columns].fillna(value=1)\n",
    "\n",
    "    primary_data_name = exam_columns[0]\n",
    "    primary_exam_data = exam_summary_dfs[primary_data_name].to_numpy()\n",
    "\n",
    "    for i, data_name in enumerate(exam_columns[1:], start=1):\n",
    "        exam_data = exam_summary_dfs[data_name].to_numpy()\n",
    "\n",
    "        print('-'*15 + formula + '-'*15)\n",
    "        print(f\"{TechniqueNameMap[primary_data_name]} v.s. {TechniqueNameMap[data_name]}\")\n",
    "        print(f\"{len(primary_exam_data)}, {len(exam_data)}\")\n",
    "\n",
    "        if len(primary_exam_data) == len(exam_data):\n",
    "            sorted_primary_exam_data = np.sort(primary_exam_data)\n",
    "            filtered_primary_exam_data = sorted_primary_exam_data[sorted_primary_exam_data <= 0.2]\n",
    "            \n",
    "            filtered_length = len(filtered_primary_exam_data)\n",
    "            \n",
    "            sorted_exam_data = np.sort(exam_data)\n",
    "            filtered_exam_data = sorted_exam_data[:filtered_length]\n",
    "            \n",
    "            p_value = wilcoxon(filtered_primary_exam_data, filtered_exam_data).pvalue\n",
    "            p_value_less = wilcoxon(filtered_primary_exam_data, filtered_exam_data, alternative='less').pvalue\n",
    "            p_value_greater = wilcoxon(filtered_primary_exam_data, filtered_exam_data, alternative='greater').pvalue\n",
    "            effective_size = cliffs_delta(filtered_primary_exam_data, filtered_exam_data)\n",
    "\n",
    "            comparison = f\"{TechniqueNameMap[primary_data_name]} v.s. {TechniqueNameMap[data_name]}\"\n",
    "\n",
    "            results_df = pd.concat([\n",
    "                results_df, pd.DataFrame({\n",
    "                    'Formula': [formula],\n",
    "                    'Comparison': [comparison],\n",
    "                    'P-value (two-sided)': [f\"{p_value:.4E}\"],\n",
    "                    'P-value (one-sided less)': [f\"{p_value_less:.4E}\"],\n",
    "                    'P-value (one-sided greater)': [f\"{p_value_greater:.4E}\"],\n",
    "                    'Cliff\\'s Delta': [f\"{effective_size:.4f}\"],\n",
    "                })\n",
    "            ], ignore_index=True)\n",
    "\n",
    "            outputs = [\n",
    "                f\"P-value for two-sided test: {p_value:.4E}\",\n",
    "                f\"P-value for one-sided test (less): {p_value_less:.4E}\",\n",
    "                f\"P-value for one-sided test (greater): {p_value_greater:.4E}\",\n",
    "                f\"Cliff's Delta (effect size): {effective_size:.4f}\",\n",
    "            ]\n",
    "\n",
    "            output_results = \"\\n\".join(outputs)\n",
    "            print(output_results)\n",
    "        else:\n",
    "            print(\"Warning: data length is not same.\")\n",
    "\n",
    "results_df.to_csv('./Results/StatisticAnalysis_6_threshold.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae1aa01-1ab4-45ec-9cff-de7f08dff24b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns = ['Formula', 'Comparison', \n",
    "           'P-value (two-sided)', 'P-value (one-sided less)', 'P-value (one-sided greater)', \n",
    "           'Cliff\\'s Delta']\n",
    "results_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for formula_index, formula in enumerate(flra.Formula):\n",
    "    param = {\n",
    "        \"Kill Type\": [\"kill_type3\"],\n",
    "        \"Approach\": [\"FACombination\"],\n",
    "        \"Mutation Type\": [\"MergeSus\", \"MergeMutation\", \"NeuralMutation\", \"TraditionalMutation\"],\n",
    "        \"Mutation Method\": [\"major\", \"mBERT\", \"major_SmBERT\", \"mBERT_Smajor\", \"U_mBERT_major\", \"SusDRankAvg\"],\n",
    "        \"Aggregation\": [\"max\"],\n",
    "        \"Formula\": [formula],\n",
    "        \"Tie Break\": [\"Avg\"]\n",
    "    }\n",
    "\n",
    "    exam_summary_dfs = flra.compare_exam_summary_by_param(param, \"Mutation Method\", drop_rank=False)\n",
    "    exam_columns = [col for col in exam_summary_dfs.columns if col.startswith('EXAM_')]\n",
    "    exam_columns = [exam_columns[i] for i in [4, 5]]\n",
    "    exam_summary_dfs[exam_columns] = exam_summary_dfs[exam_columns].fillna(value=1)\n",
    "\n",
    "    primary_data_name = exam_columns[0]\n",
    "    primary_exam_data = exam_summary_dfs[primary_data_name].to_numpy()\n",
    "\n",
    "    for i, data_name in enumerate(exam_columns[1:], start=1):\n",
    "        exam_data = exam_summary_dfs[data_name].to_numpy()\n",
    "\n",
    "        print('-'*15 + formula + '-'*15)\n",
    "        print(f\"{TechniqueNameMap[primary_data_name]} v.s. {TechniqueNameMap[data_name]}\")\n",
    "        print(f\"{len(primary_exam_data)}, {len(exam_data)}\")\n",
    "\n",
    "        if len(primary_exam_data) == len(exam_data):\n",
    "            sorted_primary_exam_data = np.sort(primary_exam_data)\n",
    "            filtered_primary_exam_data = sorted_primary_exam_data[sorted_primary_exam_data <= 0.2]\n",
    "            \n",
    "            filtered_length = len(filtered_primary_exam_data)\n",
    "            \n",
    "            sorted_exam_data = np.sort(exam_data)\n",
    "            filtered_exam_data = sorted_exam_data[:filtered_length]\n",
    "            \n",
    "            p_value = wilcoxon(filtered_primary_exam_data, filtered_exam_data).pvalue\n",
    "            p_value_less = wilcoxon(filtered_primary_exam_data, filtered_exam_data, alternative='less').pvalue\n",
    "            p_value_greater = wilcoxon(filtered_primary_exam_data, filtered_exam_data, alternative='greater').pvalue\n",
    "            effective_size = cliffs_delta(filtered_primary_exam_data, filtered_exam_data)\n",
    "            comparison = f\"{TechniqueNameMap[primary_data_name]} v.s. {TechniqueNameMap[data_name]}\"\n",
    "\n",
    "            results_df = pd.concat([\n",
    "                results_df, pd.DataFrame({\n",
    "                    'Formula': [formula],\n",
    "                    'Comparison': [comparison],\n",
    "                    'P-value (two-sided)': [f\"{p_value:.4E}\"],\n",
    "                    'P-value (one-sided less)': [f\"{p_value_less:.4E}\"],\n",
    "                    'P-value (one-sided greater)': [f\"{p_value_greater:.4E}\"],\n",
    "                    'Cliff\\'s Delta': [f\"{effective_size:.4f}\"],\n",
    "                })\n",
    "            ], ignore_index=True)\n",
    "\n",
    "            outputs = [\n",
    "                f\"P-value for two-sided test: {p_value:.4E}\",\n",
    "                f\"P-value for one-sided test (less): {p_value_less:.4E}\",\n",
    "                f\"P-value for one-sided test (greater): {p_value_greater:.4E}\",\n",
    "                f\"Cliff's Delta (effect size): {effective_size:.4f}\",\n",
    "            ]\n",
    "\n",
    "            output_results = \"\\n\".join(outputs)\n",
    "            print(output_results)\n",
    "        else:\n",
    "            print(\"Warning: data length is not same.\")\n",
    "\n",
    "# 将结果写入CSV文件\n",
    "results_df.to_csv('./Results/StatisticAnalysis_2_threshold.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da6a745-59aa-4bd3-9da6-caab217b783e",
   "metadata": {},
   "source": [
    "## **Overlap Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e694216-37d5-4898-976f-0f7fe8205366",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "palette_Tighnari = GIColorPalette.get_palette('Tighnari',format=\"hex\")\n",
    "palette_Nilou = GIColorPalette.get_palette('Nilou',format=\"hex\")\n",
    "palette_3 = [palette_Tighnari[2], palette_Tighnari[5], palette_Nilou[4]]\n",
    "palette_2 = palette_3[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ccfa01-4612-4cd0-b5e9-cb80bb2388f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_MaxRankFaults(exam_summary_dfs, MaxRank, Rank_colname):\n",
    "    MaxRank_faults_df = exam_summary_dfs[exam_summary_dfs[Rank_colname] <= MaxRank].copy()\n",
    "    MaxRank_faults_df.loc[:, 'combined'] = MaxRank_faults_df['Project'].astype(str) + '_' + MaxRank_faults_df['Version'].astype(str) + '_' + MaxRank_faults_df['faulty_entity'].astype(str)\n",
    "    MaxRank_faults_set = set(MaxRank_faults_df['combined'])\n",
    "    return MaxRank_faults_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ed8770-7abf-4e94-992e-f9bf95201d39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2, venn3\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "title_fontsize = 60\n",
    "label_fontsize = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3802a4ef-b370-462c-8cfb-8bc85f241ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "flra = FLResultAnalyst()\n",
    "flra.DatasetVersion[flra.dataset]=\"v2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e74940a-813b-40f2-a91c-ebb9d1f9ca81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TechniqueNameMap = {\n",
    "    \"Rank_major\":\"Traditional-MBFL\",\n",
    "    \"Rank_mBERT\":\"Neural-MBFL\",\n",
    "    \"Rank_major_SmBERT\":\"NeuraIntegra-MBFL$_{Mutation}^{Traditional-Center}$\",\n",
    "    \"Rank_mBERT_Smajor\":\"NeuraIntegra-MBFL$_{Mutation}^{Neural-Center}$\",\n",
    "    \"Rank_U_mBERT_major\":\"NeuraIntegra-MBFL$_{Mutation}^{Union}$\",\n",
    "    \"Rank_SusDRankAvg\":\"NeuraIntegra-MBFL$_{Suspiciousness}$\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af463278-fa42-409f-8b57-c137fd2fc884",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for MaxRank in [1, 3, 5]:\n",
    "    fig, axs = plt.subplots(1, 7, figsize=(70, 10))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    for formula_index, formula in enumerate(flra.Formula):\n",
    "        param = {\n",
    "            \"Kill Type\": [\"kill_type3\"],\n",
    "            \"Approach\": [\"FACombination\"],\n",
    "            \"Mutation Type\": [\"MergeSus\", \"MergeMutation\", \"NeuralMutation\", \"TraditionalMutation\"],\n",
    "            \"Mutation Method\": [\"major\", \"mBERT\", \"major_SmBERT\", \"mBERT_Smajor\", \"U_mBERT_major\", \"SusDRankAvg\"],\n",
    "            \"Aggregation\": [\"max\"],\n",
    "            \"Formula\": [formula],\n",
    "            \"Tie Break\": [\"Avg\"]\n",
    "        }\n",
    "\n",
    "        exam_summary_dfs = flra.compare_exam_summary_by_param(param, \"Mutation Method\", drop_rank=False)\n",
    "        rank_columns = [col for col in exam_summary_dfs.columns if col.startswith('Rank_')]\n",
    "        rank_columns = [rank_columns[i] for i in [0, 4, 5]]\n",
    "\n",
    "        major_set = get_MaxRankFaults(exam_summary_dfs, MaxRank, Rank_colname='Rank_major')\n",
    "        mBERT_set = get_MaxRankFaults(exam_summary_dfs, MaxRank, Rank_colname='Rank_mBERT')\n",
    "        SusDRankAvg_set = get_MaxRankFaults(exam_summary_dfs, MaxRank, Rank_colname='Rank_SusDRankAvg')\n",
    "        \n",
    "        sets = [mBERT_set, major_set, SusDRankAvg_set]\n",
    "        sets_labels = (TechniqueNameMap[\"Rank_mBERT\"], TechniqueNameMap[\"Rank_major\"], TechniqueNameMap[\"Rank_SusDRankAvg\"])\n",
    "        \n",
    "        venn_diagram = venn3(\n",
    "            [mBERT_set, major_set, SusDRankAvg_set], \n",
    "            set_labels=(TechniqueNameMap[\"Rank_mBERT\"], TechniqueNameMap[\"Rank_major\"], TechniqueNameMap[\"Rank_SusDRankAvg\"]),\n",
    "            alpha=0.5,\n",
    "            ax=axs[formula_index]\n",
    "        )\n",
    "\n",
    "        total = len(major_set | mBERT_set | SusDRankAvg_set)\n",
    "        for region in ['100', '010', '001', '110', '101', '011', '111']:\n",
    "            if venn_diagram.get_label_by_id(region):\n",
    "                venn_diagram.get_label_by_id(region).set_fontsize(label_fontsize)\n",
    "            label = venn_diagram.get_label_by_id(region)\n",
    "            if label:\n",
    "                count = int(label.get_text())\n",
    "                percentage = (count / total) * 100\n",
    "                label.set_text(f\"{count}\\n({percentage:.1f}%)\")\n",
    "\n",
    "        venn_diagram.get_label_by_id('100').set_position((-0.5, 0.22))\n",
    "        venn_diagram.get_label_by_id('010').set_position((0.5, 0.22))\n",
    "        venn_diagram.get_label_by_id('101').set_position((-0.35, -0.05))\n",
    "        venn_diagram.get_label_by_id('111').set_position((0.08, -0.05))\n",
    "        venn_diagram.get_label_by_id('011').set_position((0.43, -0.05))\n",
    "        venn_diagram.get_label_by_id('001').set_position((0.08, -0.48))\n",
    "        \n",
    "        venn_diagram.get_patch_by_id('100').set_facecolor(palette_3[0])  \n",
    "        venn_diagram.get_patch_by_id('100').set_alpha(0.7)  \n",
    "        \n",
    "        venn_diagram.get_patch_by_id('010').set_facecolor(palette_3[1])  \n",
    "        venn_diagram.get_patch_by_id('010').set_alpha(0.7)  \n",
    "        \n",
    "        venn_diagram.get_patch_by_id('001').set_facecolor(palette_3[2])  \n",
    "        venn_diagram.get_patch_by_id('001').set_alpha(0.7)  \n",
    "\n",
    "        positions = [(0.7, 0.53), (-0.7, 0.53), (0, -0.63)]  \n",
    "        for label, pos, label_text in zip(venn_diagram.set_labels, positions, (TechniqueNameMap[\"Rank_major\"], TechniqueNameMap[\"Rank_mBERT\"], TechniqueNameMap[\"Rank_SusDRankAvg\"])):\n",
    "            label.set_fontsize(label_fontsize)\n",
    "            label.set_position(pos)\n",
    "            label.set_text(label_text)\n",
    "\n",
    "        axs[formula_index].set_axis_on()\n",
    "        axs[formula_index].text(0.5, 0.1, formula, fontsize=title_fontsize, ha='center', va='top', transform=axs[formula_index].transAxes)\n",
    "        axs[formula_index].set_xlim(-0.73, 0.73)\n",
    "        axs[formula_index].set_ylim(-0.9, 0.63)\n",
    "\n",
    "        for spine in axs[formula_index].spines.values():\n",
    "            spine.set_edgecolor('gray')  \n",
    "            spine.set_linewidth(3)  \n",
    "\n",
    "    plt.tight_layout(w_pad=2.5)\n",
    "    plt.savefig(f\"./Results/OverlapAnalysis/Venn_3_Top_{MaxRank}.pdf\", format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e941a794-61b1-41c0-9f71-68486a6410af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for MaxRank in [1, 3, 5]:\n",
    "    fig, axs = plt.subplots(1, 7, figsize=(70, 10))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    for formula_index, formula in enumerate(flra.Formula):\n",
    "        param = {\n",
    "            \"Kill Type\": [\"kill_type3\"],\n",
    "            \"Approach\": [\"FACombination\"],\n",
    "            \"Mutation Type\": [\"MergeSus\", \"MergeMutation\", \"NeuralMutation\", \"TraditionalMutation\"],\n",
    "            \"Mutation Method\": [\"major\", \"mBERT\", \"major_SmBERT\", \"mBERT_Smajor\", \"U_mBERT_major\", \"SusDRankAvg\"],\n",
    "            \"Aggregation\": [\"max\"],\n",
    "            \"Formula\": [formula],\n",
    "            \"Tie Break\": [\"Avg\"]\n",
    "        }\n",
    "\n",
    "        exam_summary_dfs = flra.compare_exam_summary_by_param(param, \"Mutation Method\", drop_rank=False)\n",
    "        rank_columns = [col for col in exam_summary_dfs.columns if col.startswith('Rank_')]\n",
    "        rank_columns = [rank_columns[i] for i in [4, 5]]\n",
    "\n",
    "        major_set = get_MaxRankFaults(exam_summary_dfs, MaxRank, Rank_colname='Rank_major')\n",
    "        mBERT_set = get_MaxRankFaults(exam_summary_dfs, MaxRank, Rank_colname='Rank_mBERT')\n",
    "        \n",
    "        sets = [mBERT_set, major_set]\n",
    "        sets_labels = (TechniqueNameMap[\"Rank_mBERT\"], TechniqueNameMap[\"Rank_major\"])\n",
    "        \n",
    "        venn_diagram = venn2(\n",
    "            [mBERT_set, major_set], \n",
    "            set_labels=(TechniqueNameMap[\"Rank_mBERT\"], TechniqueNameMap[\"Rank_major\"]),\n",
    "            alpha=0.5,\n",
    "            ax=axs[formula_index]\n",
    "        )\n",
    "\n",
    "        total = len(major_set | mBERT_set)\n",
    "        for region in ['10', '01', '11']:\n",
    "            if venn_diagram.get_label_by_id(region):\n",
    "                venn_diagram.get_label_by_id(region).set_fontsize(label_fontsize + 4)\n",
    "            label = venn_diagram.get_label_by_id(region)\n",
    "            if label:\n",
    "                count = int(label.get_text())\n",
    "                percentage = (count / total) * 100\n",
    "                label.set_text(f\"{count}\\n({percentage:.2f}%)\")\n",
    "\n",
    "        venn_diagram.get_label_by_id('10').set_position((-0.45, 0))\n",
    "        venn_diagram.get_label_by_id('01').set_position((0.48, 0))\n",
    "        venn_diagram.get_label_by_id('11').set_position((0.08, 0))\n",
    "        \n",
    "        venn_diagram.get_patch_by_id('10').set_facecolor(palette_2[0])  \n",
    "        venn_diagram.get_patch_by_id('10').set_alpha(0.7)  \n",
    "        \n",
    "        venn_diagram.get_patch_by_id('01').set_facecolor(palette_2[1])  \n",
    "        venn_diagram.get_patch_by_id('01').set_alpha(0.7)  \n",
    "        \n",
    "        positions = [(0.68, -0.5), (-0.68, -0.5)]  \n",
    "        for label, pos, label_text in zip(venn_diagram.set_labels, positions, (TechniqueNameMap[\"Rank_major\"], TechniqueNameMap[\"Rank_mBERT\"])):\n",
    "            label.set_fontsize(label_fontsize + 4)\n",
    "            label.set_position(pos)\n",
    "            label.set_text(label_text)\n",
    "\n",
    "        axs[formula_index].set_axis_on()\n",
    "        axs[formula_index].text(0.5, 0.1, formula, fontsize=title_fontsize, ha='center', va='top', transform=axs[formula_index].transAxes)\n",
    "        axs[formula_index].set_xlim(-0.68, 0.68)\n",
    "        axs[formula_index].set_ylim(-0.8, 0.5)\n",
    "\n",
    "        for spine in axs[formula_index].spines.values():\n",
    "            spine.set_edgecolor('gray')  \n",
    "            spine.set_linewidth(3)  \n",
    "\n",
    "    plt.tight_layout(w_pad=7.5)\n",
    "    plt.savefig(f\"./Results/OverlapAnalysis/Venn_2_Top_{MaxRank}.pdf\", format='pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5be1fc2-7113-43de-ad6c-174f8c45fb9e",
   "metadata": {},
   "source": [
    "## **Repair Pattern Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6f419c-5906-41a0-92af-9cbd0eb7d36a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "palette_Tighnari = GIColorPalette.get_palette('Tighnari',format=\"hex\")\n",
    "palette_Nilou = GIColorPalette.get_palette('Nilou',format=\"hex\")\n",
    "palette_3 = [palette_Tighnari[2], palette_Tighnari[5], palette_Nilou[4]]\n",
    "palette_2 = palette_3[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7235dd8-a9f3-443c-92b0-438689f512c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_patterns(localized_bugs, repair_patterns):\n",
    "    pattern_count = {}\n",
    "    pattern_bugs = {}\n",
    "    for bug in localized_bugs:\n",
    "        project = bug.split('_')[0]\n",
    "        bug_id = bug.split('_')[1]\n",
    "        key = f'{project}_{bug_id}'\n",
    "        if key in repair_patterns:\n",
    "            for pattern in repair_patterns[key]:\n",
    "                if pattern in pattern_count:\n",
    "                    pattern_count[pattern] += 1\n",
    "                    pattern_bugs[pattern].append(key)\n",
    "                else:\n",
    "                    pattern_count[pattern] = 1\n",
    "                    pattern_bugs[pattern] = [key]\n",
    "    return pattern_count, pattern_bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01a3cb7-9991-4308-8c4c-31527109a5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(D4J / \"RepairInfo.json\", mode = \"r\") as fp:\n",
    "    repair_json = json.load(fp)\n",
    "repair_patterns = {}\n",
    "for bug_info in repair_json:\n",
    "    repair_patterns[f\"{bug_info['project']}_{bug_info['bugId']}\"] = bug_info['repairPatterns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6865be61-f0b3-47a6-bb9b-fb8d245569ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flra = FLResultAnalyst()\n",
    "\n",
    "mBERT_localized_bugs = {}  \n",
    "major_localized_bugs = {}  \n",
    "\n",
    "MaxRank = 5  \n",
    "\n",
    "for formula in flra.Formula:\n",
    "    param = {\n",
    "        \"Kill Type\": [\"kill_type3\"],\n",
    "        \"Approach\": [\"FACombination\"],\n",
    "        \"Mutation Type\": [\"NeuralMutation\", \"TraditionalMutation\"],\n",
    "        \"Mutation Method\": [\"mBERT\", \"major\"],\n",
    "        \"Aggregation\": [\"max\"],\n",
    "        \"Formula\": [formula],\n",
    "        \"Tie Break\": [\"Avg\"]\n",
    "    }\n",
    "    exam_summary_dfs = flra.compare_exam_summary_by_param(param, \"Mutation Method\", drop_rank=False)\n",
    "\n",
    "    rank_columns = [col for col in exam_summary_dfs.columns if col.startswith('Rank_')]\n",
    "\n",
    "    localized_bug_MaxRank_sets = {}\n",
    "    for column in rank_columns:\n",
    "        localized_bug_MaxRank = set(\n",
    "            exam_summary_dfs[exam_summary_dfs[column] <= MaxRank]\n",
    "            .apply(lambda row: f\"{row['Project']}_{row['Version']}\", axis=1)\n",
    "        )\n",
    "        localized_bug_MaxRank_sets[column] = localized_bug_MaxRank\n",
    "\n",
    "    mBERT_localized_bugs[formula] = localized_bug_MaxRank_sets['Rank_mBERT']\n",
    "    major_localized_bugs[formula] = localized_bug_MaxRank_sets['Rank_major']\n",
    "\n",
    "mBERT_unique_bugs = {}\n",
    "major_unique_bugs = {}\n",
    "for formula in mBERT_localized_bugs.keys():\n",
    "    mBERT_unique_bugs[formula] = mBERT_localized_bugs[formula] - major_localized_bugs[formula]\n",
    "    major_unique_bugs[formula] = major_localized_bugs[formula] - mBERT_localized_bugs[formula]\n",
    "    \n",
    "mBERT_unique_bugs[\"Union\"] = set.union(*mBERT_unique_bugs.values())\n",
    "major_unique_bugs[\"Union\"] = set.union(*major_unique_bugs.values())\n",
    "\n",
    "mBERT_unique_bugs[\"Intersection\"] = set.intersection(*mBERT_unique_bugs.values())\n",
    "major_unique_bugs[\"Intersection\"] = set.intersection(*major_unique_bugs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5144fb-5ae1-4df0-9437-76d6c220e2e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "title_fontsize = 36\n",
    "label_fontsize = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d116a60-50d2-418e-849e-6d72783c76a1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for formula in mBERT_unique_bugs.keys():\n",
    "    mBERT_pattern_count, mBERT_pattern_bugs = count_patterns(mBERT_unique_bugs[formula], repair_patterns)\n",
    "    major_pattern_count, major_pattern_bugs = count_patterns(major_unique_bugs[formula], repair_patterns)\n",
    "\n",
    "    all_patterns = set(mBERT_pattern_count.keys()) | set(major_pattern_count.keys())\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'Pattern': list(all_patterns),\n",
    "        'mBERT': [mBERT_pattern_count.get(pattern, 0) for pattern in all_patterns],\n",
    "        'major': [major_pattern_count.get(pattern, 0) for pattern in all_patterns]\n",
    "    })\n",
    "\n",
    "    df['Total'] = df['mBERT'] + df['major']\n",
    "    df['mBERT_Rel_Percent'] = df['mBERT'] / df['Total'] * 100\n",
    "    df['major_Rel_Percent'] = df['major'] / df['Total'] * 100\n",
    "\n",
    "    df['Total'] = df['mBERT'] + df['major']\n",
    "    df['mBERT_Rel_Percent'] = df['mBERT'] / df['Total'] * 100\n",
    "    df['major_Rel_Percent'] = df['major'] / df['Total'] * 100\n",
    "\n",
    "    df_sorted_rel = df.sort_values(by=['mBERT_Rel_Percent', 'major_Rel_Percent', 'Pattern'], ascending=[True, False, False])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(16, 16))\n",
    "    ax.barh(df_sorted_rel['Pattern'], df_sorted_rel['mBERT_Rel_Percent'], color=palette_2[0], label='Neural-MBFL')\n",
    "    ax.barh(df_sorted_rel['Pattern'], df_sorted_rel['major_Rel_Percent'], left=df_sorted_rel['mBERT_Rel_Percent'], color=palette_2[1], label='Traditional-MBFL')\n",
    "\n",
    "    ax.tick_params(axis='both', labelsize=label_fontsize)\n",
    "    ax.set_xlabel('Percentage (%)', fontsize=label_fontsize)\n",
    "    ax.set_ylim(-1, df.shape[0])\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='upper center', ncol=2, bbox_to_anchor=(0.627, 1.015), fontsize=label_fontsize)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.savefig(f\"./Results/RepairPattern/RepairPatterns_2_MAX_{formula}.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
